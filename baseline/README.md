# 基线方法说明

本项目实现了以下三种基线方法，用于比较和评估不同的检索增强生成（RAG）技术：

## 1. AdaComp

**AdaComp** 是一种自适应压缩方法，专门用于分布式深度学习系统。该方法通过动态调整压缩率来优化通信效率，特别适用于参数服务器模型中的分布式随机梯度下降（SGD）训练。

**主要特点：**
- 自适应压缩率调整
- 优化分布式训练通信效率
- 适用于大规模深度学习模型训练

**参考链接：** [AdaComp 项目主页](https://anonymous.4open.science/r/AdaComp-8C0C/README.md)

## 2. CRAG (Corrective Retrieval Augmented Generation)

**CRAG** 是一种纠正性检索增强生成方法，旨在通过引入检索评估器来评估检索文档的整体质量，从而提高生成模型的鲁棒性。根据评估结果，系统会触发不同的知识检索操作来增强生成性能。

**主要特点：**
- 检索质量评估机制
- 纠正性检索策略
- 提高生成鲁棒性
- 动态知识检索操作

**参考链接：** [CRAG GitHub 仓库](https://github.com/HuskyInSalt/CRAG)

## 3. Self-RAG (Self-Reflective Retrieval-Augmented Generation)

**Self-RAG** 是一种通过自我反思来学习检索、生成和批判的框架。该方法使语言模型能够在生成过程中自适应地检索相关文档，并对生成内容进行自我评估，从而提高输出质量和事实性。

**主要特点：**
- 自我反思机制
- 自适应文档检索
- 生成内容自我评估
- 提高事实性和质量
- 端到端训练框架

**参考链接：** [Self-RAG 项目主页](https://selfrag.github.io/)

## 目录结构

```
code/
├── Adacomp/          # AdaComp 方法实现
├── CRAG/            # CRAG 方法实现
├── SELFRAG/         # Self-RAG 方法实现
└── README.md        # 本说明文件
```

## 使用方法

每种基线方法的具体使用方法请参考各自目录下的实现代码和文档。这些方法可以用于比较不同RAG技术的性能，帮助选择最适合特定任务的检索增强生成策略。

## 注意事项

- 请确保在使用前已正确安装所有依赖项
- 不同方法可能需要不同的模型和数据集配置
- 建议在相同的数据集和评估指标下进行比较实验
