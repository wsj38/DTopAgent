# DPR Retrieval System

This directory contains the Dense Passage Retrieval (DPR) system implementation for the AdaComp SPARK project. The system uses DPR models to encode questions and documents into dense vector representations, enabling efficient semantic search through Elasticsearch.

## üèóÔ∏è System Architecture

```
DPRÊ£ÄÁ¥¢/
‚îú‚îÄ‚îÄ create_index.py    # Create Elasticsearch index with DPR mappings
‚îú‚îÄ‚îÄ insert.py          # Insert documents with DPR embeddings
‚îú‚îÄ‚îÄ search.py          # Search documents using DPR question encoder
‚îú‚îÄ‚îÄ process_time.py    # Process and format web search data
‚îî‚îÄ‚îÄ mapping.json       # Elasticsearch index mapping configuration
```

## üöÄ Quick Start

### Prerequisites

```bash
# Install required packages
pip install torch transformers elasticsearch tqdm pillow

# Ensure you have:
# - CUDA-compatible GPU (recommended)
# - Elasticsearch server running
# - DPR models downloaded
```

### Complete Workflow

```bash
# 1. Create Elasticsearch index
python create_index.py

# 2. Process and format input data
python process_time.py --input input.json --output formatted_data.json

# 3. Insert documents with DPR embeddings
python insert.py --input formatted_data.json --url "http://localhost:9200" --index "dpr_index"

# 4. Search using DPR question encoder
python search.py --input questions.json --output results.json --url "http://localhost:9200" --index "dpr_index"
```

## üìã Detailed Components

### 1. Index Creation (`create_index.py`)

**Purpose**: Create Elasticsearch index with proper mappings for DPR embeddings.

**Key Features**:
- Configurable index settings (shards, replicas, refresh interval)
- Dense vector field for 768-dimensional DPR embeddings
- Cosine similarity for vector search
- Support for various field types and analyzers

**Usage**:
```python
# Configure Elasticsearch connection
es = Elasticsearch(
    'http://localhost:9200',
    basic_auth=("username", "password"),
)

# Create index with DPR mapping
idxnm = "dpr_index"
es.indices.create(index=idxnm, body=mapping, request_timeout=60)
```

**Configuration**:
- **Shards**: 2 (adjustable based on data size)
- **Replicas**: 0 (for development, increase for production)
- **Refresh Interval**: 1000ms
- **Vector Dimensions**: 768 (DPR embedding size)

### 2. Data Processing (`process_time.py`)

**Purpose**: Process web search results and format them for DPR indexing.

**Key Features**:
- Text chunking with word and sentence boundaries
- Timeout handling for large documents
- Multiprocessing support for parallel processing
- Context list generation for better retrieval

**Usage**:
```bash
python process_time.py \
    --input web_search_results.json \
    --output formatted_data.json
```

**Text Processing**:
- **Max Words**: 300 per chunk (configurable)
- **Sentence Boundary Detection**: Uses regex patterns
- **Reference Removal**: Removes citation numbers `[1]`, `[2]`, etc.
- **Timeout Protection**: 30-second timeout per document

**Input Format**:
```json
[
  {
    "question": "What is machine learning?",
    "query": "machine learning definition",
    "results": [
      {
        "title": "Machine Learning - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Machine_learning",
        "context": "Machine learning is a subset of artificial intelligence...",
        "snippet": "Machine learning algorithms build models..."
      }
    ]
  }
]
```

**Output Format**:
```json
[
  {
    "question_id": "question_0",
    "question": "What is machine learning?",
    "query": "machine learning definition",
    "results": [
      {
        "title": "Machine Learning - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Machine_learning",
        "context": "Machine learning is a subset of artificial intelligence...",
        "context_list": [
          "Machine learning is a subset of artificial intelligence...",
          "It focuses on algorithms that can learn from data..."
        ],
        "question_id": "question_0"
      }
    ]
  }
]
```

### 3. Document Insertion (`insert.py`)

**Purpose**: Insert processed documents into Elasticsearch with DPR context embeddings.

**Key Features**:
- Uses DPR Context Encoder for document embeddings
- Bulk insertion for efficiency
- Error handling and progress tracking
- GPU acceleration support

**Usage**:
```bash
python insert.py \
    --input formatted_data.json \
    --url "http://localhost:9200" \
    --index "dpr_index" \
    --username "elastic" \
    --password "password"
```

**Model Configuration**:
- **Model**: `dpr-ctx_encoder-single-nq-base`
- **Max Length**: 512 tokens
- **Device**: CUDA (GPU acceleration)
- **Batch Processing**: Bulk insertion for efficiency

**Document Structure**:
```json
{
  "title": "Document Title",
  "content": "Document content text...",
  "context_embedding": [0.1, 0.2, ..., 0.768],  // 768-dimensional vector
  "question_id": "question_866_0"
}
```

### 4. Document Search (`search.py`)

**Purpose**: Search documents using DPR question encoder for semantic similarity.

**Key Features**:
- Uses DPR Question Encoder for query embeddings
- KNN (K-Nearest Neighbors) search in Elasticsearch
- Filtering by question_id for targeted search
- Similarity scoring and ranking

**Usage**:
```bash
python search.py \
    --input questions.json \
    --output results.json \
    --url "http://localhost:9200" \
    --index "dpr_index" \
    --username "elastic" \
    --password "password"
```

**Search Configuration**:
- **K**: 5 (number of results to return)
- **Num Candidates**: 10 (candidate pool size)
- **Similarity**: Cosine similarity
- **Filter**: By question_id for targeted search

**Search Query Structure**:
```json
{
  "knn": {
    "field": "context_embedding",
    "k": 5,
    "num_candidates": 10,
    "query_vector": [0.1, 0.2, ..., 0.768],
    "filter": {
      "term": {
        "question_id": "question_866_0"
      }
    }
  },
  "_source": false,
  "fields": ["title", "content"]
}
```

**Output Format**:
```json
[
  {
    "question_id": "question_866_0",
    "question": "What is machine learning?",
    "meta": [
      {
        "title": "Machine Learning - Wikipedia",
        "content": "Machine learning is a subset of artificial intelligence...",
        "score": 0.95
      }
    ]
  }
]
```

## ‚öôÔ∏è Configuration

### Elasticsearch Settings

**Index Configuration** (`mapping.json`):
```json
{
  "settings": {
    "index": {
      "number_of_shards": 2,
      "number_of_replicas": 0,
      "refresh_interval": "1000ms"
    }
  },
  "mappings": {
    "properties": {
      "title": {"type": "text", "analyzer": "standard"},
      "content": {"type": "text", "analyzer": "standard"},
      "context_embedding": {
        "type": "dense_vector",
        "dims": 768,
        "similarity": "cosine"
      },
      "question_id": {"type": "keyword"}
    }
  }
}
```

### DPR Model Configuration

**Context Encoder** (for document insertion):
- Model: `dpr-ctx_encoder-single-nq-base`
- Dimensions: 768
- Max Length: 512 tokens
- Device: CUDA

**Question Encoder** (for search):
- Model: `dpr-question_encoder-single-nq-base`
- Dimensions: 768
- Max Length: 512 tokens
- Device: CUDA

### Performance Tuning

**Elasticsearch Optimization**:
- Adjust `number_of_shards` based on data size
- Increase `number_of_replicas` for production
- Tune `refresh_interval` for real-time vs. batch updates
- Monitor cluster health and performance

**DPR Model Optimization**:
- Use GPU acceleration when available
- Batch processing for multiple documents
- Adjust `max_length` based on document length
- Consider model quantization for faster inference

## üîß Troubleshooting

### Common Issues

1. **CUDA Out of Memory**
   ```bash
   # Reduce batch size or use CPU
   export CUDA_VISIBLE_DEVICES=""  # Force CPU usage
   ```

2. **Elasticsearch Connection Errors**
   ```bash
   # Check Elasticsearch status
   curl http://localhost:9200/_cluster/health
   
   # Verify authentication
   curl -u username:password http://localhost:9200/_cluster/health
   ```

3. **Index Creation Failures**
   ```bash
   # Check if index exists
   curl http://localhost:9200/_cat/indices
   
   # Delete existing index
   curl -X DELETE http://localhost:9200/dpr_index
   ```

4. **Bulk Insertion Errors**
   ```bash
   # Check bulk operation status
   curl http://localhost:9200/_cat/indices?v
   
   # Monitor cluster health
   curl http://localhost:9200/_cluster/health?pretty
   ```

### Performance Optimization

**Elasticsearch**:
- Increase heap size for large datasets
- Use SSD storage for better I/O performance
- Optimize refresh intervals for your use case
- Monitor slow query logs

**DPR Models**:
- Use mixed precision training (FP16) for faster inference
- Implement model caching for repeated queries
- Consider model distillation for smaller models
- Use batch processing for multiple queries

## üìä Expected Performance

### Retrieval Quality
- **Top-5 Accuracy**: 85-95% (depending on dataset)
- **Response Time**: <100ms for single queries
- **Throughput**: 100+ queries/second (with proper optimization)

### Resource Requirements
- **GPU Memory**: 4GB+ (for DPR models)
- **RAM**: 8GB+ (for Elasticsearch)
- **Storage**: SSD recommended for large indices
- **CPU**: Multi-core recommended for parallel processing

## üîó Integration with SPARK

This DPR retrieval system integrates with the AdaComp SPARK pipeline:

1. **Predictor Stage**: Uses DPR search results to predict optimal K values
2. **Answer Stage**: Provides retrieved documents for answer generation
3. **Control Stage**: Evaluates retrieval quality and adjusts parameters
4. **Evaluation Stage**: Measures retrieval performance metrics

## üìÑ License

This DPR retrieval system is part of the AdaComp SPARK project. Please refer to the main project license for usage terms.

## üîó References

- [DPR Paper](https://arxiv.org/abs/2004.04906) - Dense Passage Retrieval
- [Elasticsearch Documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/)
- [Transformers Library](https://huggingface.co/docs/transformers/)
- [AdaComp SPARK Project](https://anonymous.4open.science/r/AdaComp-8C0C/)
